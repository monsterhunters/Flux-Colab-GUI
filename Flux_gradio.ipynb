{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5GWvLP3cpti9fnVVgKzEk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monsterhunters/Flux-Colab-GUI/blob/main/Flux_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install Module\n",
        "\n",
        "\n",
        "import os\n",
        "os.chdir('/content')\n",
        "os.system('git clone -b totoro4 https://github.com/camenduru/ComfyUI /content/TotoroUI')\n",
        "ROOT = \"/content/TotoroUI\"\n",
        "os.chdir(ROOT)\n",
        "!pip install -q torchsde einops diffusers accelerate gradio python-multipart==0.0.12\n",
        "os.system('pip install torchaudio==2.5.1+cu121 --index-url https://download.pytorch.org/whl/cu121')\n",
        "os.system('pip install -U xformers torch --index-url https://download.pytorch.org/whl/cu121')\n",
        "!apt -y install -qq aria2\n",
        "os.makedirs('/content/TotoroUI/models/checkpoints', exist_ok=True)\n",
        "os.makedirs('/content/TotoroUI/models/loras', exist_ok=True)\n",
        "os.makedirs('/content/TotoroUI/output', exist_ok=True)\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/flux1-dev-fp8-all-in-one.safetensors -d /content/TotoroUI/models/checkpoints -o flux1-dev-fp8-all-in-one.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/flux_realism_lora.safetensors -d /content/TotoroUI/models/loras -o flux_realism_lora.safetensors\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Cl6vDs0g8Aee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title RUN\n",
        "import random, os\n",
        "\n",
        "ROOT = \"/content/TotoroUI\"\n",
        "os.chdir(ROOT)\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import nodes\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "from totoro_extras import nodes_custom_sampler\n",
        "from totoro_extras import nodes_flux\n",
        "from totoro import model_management\n",
        "from urllib.parse import urlparse\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "\n",
        "CheckpointLoaderSimple = NODE_CLASS_MAPPINGS[\"CheckpointLoaderSimple\"]()\n",
        "LoraLoader = NODE_CLASS_MAPPINGS[\"LoraLoader\"]()\n",
        "FluxGuidance = nodes_flux.NODE_CLASS_MAPPINGS[\"FluxGuidance\"]()\n",
        "RandomNoise = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"RandomNoise\"]()\n",
        "BasicGuider = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicGuider\"]()\n",
        "KSamplerSelect = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"KSamplerSelect\"]()\n",
        "BasicScheduler = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicScheduler\"]()\n",
        "SamplerCustomAdvanced = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"SamplerCustomAdvanced\"]()\n",
        "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
        "\n",
        "CHECKPOINT_FOLDER = \"/content/TotoroUI/models/checkpoints\"\n",
        "LORA_FOLDER = \"/content/TotoroUI/models/loras\"\n",
        "\n",
        "def refresh_options():\n",
        "    # Dynamically list files in the directories\n",
        "    checkpoint_options = [f for f in os.listdir(CHECKPOINT_FOLDER) if f.endswith(('.ckpt', '.safetensors'))]\n",
        "    lora_options = [f for f in os.listdir(LORA_FOLDER) if f.endswith('.safetensors')]\n",
        "    return gr.update(choices=checkpoint_options), gr.update(choices=lora_options)\n",
        "\n",
        "def button_action(download_link, civitai_api, selection):\n",
        "    output_path = set_output_path(selection)\n",
        "    parsed_url = urlparse(download_link)\n",
        "    path_components = parsed_url.path.split(\"/\")\n",
        "    modelVersionId = path_components[-1]\n",
        "    dlink = f\"https://civitai.com/api/download/models/{modelVersionId}?token={civitai_api}\"\n",
        "    os.system(f\"aria2c -x 16 -s 16 -k 1M -d {output_path} {dlink}\")\n",
        "    return \"File downloaded successfully!\"\n",
        "\n",
        "\n",
        "def set_output_path(selection):\n",
        "    if selection == \"Checkpoint\":\n",
        "        return \"/content/TotoroUI/models/checkpoints\"\n",
        "    else:\n",
        "        return \"/content/TotoroUI/models/loras\"\n",
        "\n",
        "def get_files(folder, extensions):\n",
        "    if not os.path.exists(folder):\n",
        "        return []\n",
        "    return [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) and f.endswith(extensions)]\n",
        "\n",
        "checkpoint_options = get_files(CHECKPOINT_FOLDER, (\".ckpt\", \".safetensors\"))\n",
        "lora_options = get_files(LORA_FOLDER, (\".safetensors\",))\n",
        "\n",
        "# Fallback for empty dropdowns\n",
        "if not checkpoint_options:\n",
        "    checkpoint_options = [\"No checkpoint files found\"]\n",
        "if not lora_options:\n",
        "    lora_options = [\"No LoRA files found\"]\n",
        "\n",
        "def closestNumber(n, m):\n",
        "    q = int(n / m)\n",
        "    n1 = m * q\n",
        "    if (n * m) > 0:\n",
        "        n2 = m * (q + 1)\n",
        "    else:\n",
        "        n2 = m * (q - 1)\n",
        "    if abs(n - n1) < abs(n - n2):\n",
        "        return n1\n",
        "    return n2\n",
        "\n",
        "def generate(checkpoints_name, lora_name, positive_prompt, width, height, seed, steps, sampler_name, scheduler, guidance, lora_strength_model, lora_strength_clip):\n",
        "    try:\n",
        "        with torch.no_grad(): # Use no_grad for inference\n",
        "            # Load checkpoint dynamically\n",
        "            unet, clip, vae = CheckpointLoaderSimple.load_checkpoint(checkpoints_name)\n",
        "\n",
        "            if seed == 0:\n",
        "                seed = random.randint(0, 18446744073709551615)\n",
        "            print(f\"Seed: {seed}\")\n",
        "\n",
        "            # Load LoRA model\n",
        "            unet_lora, clip_lora = LoraLoader.load_lora(unet, clip, lora_name, lora_strength_model, lora_strength_clip)\n",
        "            cond, pooled = clip_lora.encode_from_tokens(clip_lora.tokenize(positive_prompt), return_pooled=True)\n",
        "            cond = [[cond, {\"pooled_output\": pooled}]]\n",
        "            cond = FluxGuidance.append(cond, guidance)[0]\n",
        "            noise = RandomNoise.get_noise(seed)[0]\n",
        "            guider = BasicGuider.get_guider(unet_lora, cond)[0]\n",
        "            sampler = KSamplerSelect.get_sampler(sampler_name)[0]\n",
        "            sigmas = BasicScheduler.get_sigmas(unet_lora, scheduler, steps, 1.0)[0]\n",
        "            latent_image = EmptyLatentImage.generate(closestNumber(width, 16), closestNumber(height, 16))[0]\n",
        "            sample, sample_denoised = SamplerCustomAdvanced.sample(noise, guider, sampler, sigmas, latent_image)\n",
        "            decoded = VAEDecode.decode(vae, sample)[0].detach()\n",
        "\n",
        "            # Save image to a temporary file\n",
        "            image = Image.fromarray(np.array(decoded * 255, dtype=np.uint8)[0])\n",
        "            image.save(f\"//content/TotoroUI/output/flux_{seed}.png\")\n",
        "\n",
        "            return f\"/content/TotoroUI/output/flux_{seed}.png\"\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"Error during generation: {str(e)}\"\n",
        "\n",
        "with gr.Blocks(analytics_enabled=False) as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            civitai_api = gr.Textbox(label=\"Civitai API Key\")\n",
        "            download_link = gr.Textbox(label=\"Input URL\")\n",
        "            radio_group = gr.Radio(\n",
        "                choices=[\"Checkpoint\", \"Lora\"],\n",
        "                label=\"Output folder\",\n",
        "                value=\"Checkpoint\"\n",
        "            )\n",
        "            fn=set_output_path, # Function to handle the selection\n",
        "            inputs=radio_group, # Input is the radio group\n",
        "            ordinary_button = gr.Button(\"Download File\")\n",
        "\n",
        "            positive_prompt = gr.Textbox(\n",
        "                lines=3,\n",
        "                interactive=True,\n",
        "                value=\"cute anime girl with massive fluffy fennec ears and a big fluffy tail blonde messy long hair blue eyes wearing a maid outfit with a long black dress with a gold leaf pattern and a white apron eating a slice of an apple pie in the kitchen of an old dark victorian mansion with a bright window and very expensive stuff everywhere\",\n",
        "                label=\"Prompt\"\n",
        "            )\n",
        "            width = gr.Slider(minimum=256, maximum=2048, value=1024, step=16, label=\"Width\")\n",
        "            height = gr.Slider(minimum=256, maximum=2048, value=1024, step=16, label=\"Height\")\n",
        "            seed = gr.Slider(minimum=0, maximum=18446744073709551615, value=0, step=1, label=\"Seed (0 = Random)\")\n",
        "            steps = gr.Slider(minimum=4, maximum=50, value=20, step=1, label=\"Steps\")\n",
        "            guidance = gr.Slider(minimum=0, maximum=20, value=3.5, step=0.5, label=\"Guidance\")\n",
        "            lora_strength_model = gr.Slider(minimum=0, maximum=2, value=1.0, step=0.1, label=\"LoRA Strength (Model)\")\n",
        "            lora_strength_clip = gr.Slider(minimum=0, maximum=2, value=1.0, step=0.1, label=\"LoRA Strength (Clip)\")\n",
        "            sampler_name = gr.Dropdown(\n",
        "                [\"euler\", \"heun\", \"heunpp2\", \"dpm_2\", \"lms\", \"dpmpp_2m\", \"ipndm\", \"deis\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"],\n",
        "                label=\"Sampler Name\",\n",
        "                value=\"euler\"\n",
        "            )\n",
        "            scheduler = gr.Dropdown(\n",
        "                [\"normal\", \"sgm_uniform\", \"simple\", \"ddim_uniform\"],\n",
        "                label=\"Scheduler\",\n",
        "                value=\"simple\"\n",
        "            )\n",
        "\n",
        "\n",
        "        with gr.Column():\n",
        "            refresh_button = gr.Button(\"Refresh Checkpoint/Lora\")\n",
        "            checkpoint_dropdown = gr.Dropdown(label=\"Checkpoint File\", choices=checkpoint_options)\n",
        "            lora_dropdown = gr.Dropdown(label=\"LoRA File\", choices=lora_options)\n",
        "            generate_button = gr.Button(\"Generate\")\n",
        "            output_image = gr.Image(label=\"Generated Image\", interactive=False)\n",
        "            status_message = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "    # Link buttons to actions\n",
        "    ordinary_button.click(\n",
        "        fn=button_action,\n",
        "        inputs=[download_link, civitai_api, radio_group],\n",
        "        outputs=status_message\n",
        "    )\n",
        "\n",
        "    refresh_button.click(\n",
        "        fn=refresh_options,\n",
        "        outputs=[checkpoint_dropdown, lora_dropdown]\n",
        "    )\n",
        "\n",
        "    generate_button.click(\n",
        "        fn=generate,\n",
        "        inputs=[\n",
        "            checkpoint_dropdown,\n",
        "            lora_dropdown,\n",
        "            positive_prompt,\n",
        "            width,\n",
        "            height,\n",
        "            seed,\n",
        "            steps,\n",
        "            sampler_name,\n",
        "            scheduler,\n",
        "            guidance,\n",
        "            lora_strength_model,\n",
        "            lora_strength_clip\n",
        "        ],\n",
        "        outputs=output_image\n",
        "    )\n",
        "\n",
        "demo.queue().launch(inline=False, share=True, debug=True, allowed_paths=[\"/content/TotoroUI/output\")\n",
        "demo.queue().launch(allowed_paths=[\"/content/TotoroUI/output\"])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9XFTL3lxXNbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Clear VRAM\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_max_memory_allocated()\n",
        "torch.cuda.reset_accumulated_memory_stats()\n",
        "\n",
        "import gc\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gq4JJycJOUQf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}